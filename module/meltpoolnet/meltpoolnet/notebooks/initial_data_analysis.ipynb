{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vupfd40eUGm0"
   },
   "source": [
    "# Machine Learning for Additive Manufacturing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hnicu28vUGm1"
   },
   "source": [
    "Load in relevant modules\n",
    "\n",
    "\n",
    "python package dependencies: ```mendeleev, matplotlib, pandas, numpy, pylab, pprint, sklearn, scipy, os```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpjSZzo2UGm3",
    "outputId": "8d6a617a-c45e-4d9d-f29d-3608c0df78ee"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from pprint import pprint\n",
    "from meltpoolnet.utils.plotting_utils import frame_tick\n",
    "%matplotlib inline\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mINPDSBmUGm6"
   },
   "source": [
    "# Load in data, perform basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhE9tnunUGm6",
    "outputId": "017e1ba1-43c0-4d18-feed-6a5251f17094"
   },
   "outputs": [],
   "source": [
    "# Load in the csv data, download from Google Sheets and store in directory\n",
    "dataset_dir = os.path.join(os.path.abspath(''), '../../', 'datasets')\n",
    "csv = pd.read_csv(os.path.join(dataset_dir, 'meltpoolgeometry.csv')) \n",
    "csv1 = pd.read_csv(os.path.join(dataset_dir, 'meltpoolgeometry.csv'))\n",
    "csv2 = pd.read_csv(os.path.join(dataset_dir, 'meltpoolclassification.csv'))\n",
    "regressioncsv =  csv1\n",
    "class_csv = csv1.append(csv2)\n",
    "regressioncsv =  csv1\n",
    "class_csv = csv1.append(csv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qcn5QY8pUGm7",
    "outputId": "cd3f5bbf-358d-4857-d9e9-692d076acdae"
   },
   "outputs": [],
   "source": [
    "all_depths = csv['depth of meltpool']\n",
    "all_velocity = csv['Velocity']\n",
    "all_power = csv['Power']\n",
    "print(len(csv))\n",
    "csv = csv[all_velocity < 3000][all_power < 3000]\n",
    "print(len(csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_depths = csv['depth of meltpool']\n",
    "all_velocity = csv['Velocity']\n",
    "all_power = csv['Power']\n",
    "print(len(csv))\n",
    "csv = csv[all_velocity < 3000][all_power < 3000]\n",
    "print(len(csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSfTfYQ6UGm8",
    "outputId": "31a6dbc6-7a86-4585-c165-48f4e34aefcd"
   },
   "outputs": [],
   "source": [
    "dpi = 300\n",
    "fig = plt.figure(figsize = [4,3], dpi = dpi)\n",
    "plt.scatter(all_power, all_depths, edgecolors = 'k')\n",
    "\n",
    "plt.xticks(fontsize = 8)\n",
    "plt.yticks(fontsize = 8)\n",
    "frame_tick()\n",
    "plt.xlabel(r'Laser Power (W)')\n",
    "plt.ylabel(r'Melt Pool Depths ($\\mu m$)')\n",
    "plt.title('Entire Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmu6n7HZUGm9",
    "outputId": "a89e211d-f6ee-449b-b135-829a162bdc6e"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = [4,3], dpi = dpi)\n",
    "plt.scatter(all_velocity, all_depths, edgecolors = 'k')\n",
    "\n",
    "plt.xticks(fontsize = 8)\n",
    "plt.yticks(fontsize = 8)\n",
    "frame_tick()\n",
    "plt.xlabel(r'Laser Velocity ($mm/s$)')\n",
    "plt.ylabel(r'Melt Pool Depths ($\\mu m$)')\n",
    "plt.title('Entire Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAMitmErUGm9",
    "outputId": "adcb3a8f-61c9-4be3-c1f6-2b424d299113"
   },
   "outputs": [],
   "source": [
    "# Plot power vs velocity, color by melt pool depths\n",
    "# Note this is misleading, as it takes into account different processes\n",
    "\n",
    "fig = plt.figure(figsize = [4,3], dpi = dpi)\n",
    "plt.scatter(all_power, all_velocity, c = all_depths, cmap = 'jet', edgecolors='k', vmin = 0, vmax = 500)\n",
    "plt.xticks(fontsize = 8)\n",
    "plt.yticks(fontsize = 8)\n",
    "frame_tick()\n",
    "plt.xlabel(r'Power ($W$)')\n",
    "plt.ylabel(r'Velocity ($mm/s$)')\n",
    "cbar =plt.colorbar()\n",
    "cbar.ax.set_ylabel(r'Melt Depth ($\\mu m$)', rotation=270, labelpad=10)\n",
    "plt.title('Overall Dataset Distribution')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDCiqIp3UGm-",
    "outputId": "505eb3de-9fd7-44eb-f899-5ee24cee7ae1"
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize = [4,3], dpi = dpi)\n",
    "plt.hist(all_power, edgecolor = 'k', bins = 50)\n",
    "plt.xticks(fontsize = 8)\n",
    "plt.yticks(fontsize = 8)\n",
    "frame_tick()\n",
    "plt.xlabel(r'Power ($W$)')\n",
    "plt.ylabel(r'Occurence')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4B-R0UXUGm-",
    "outputId": "1e054ea0-c5b4-4896-d262-6dcc14d7f5a6"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = [4,3], dpi = dpi)\n",
    "plt.hist(all_velocity, edgecolor = 'k', bins = 30)\n",
    "plt.xticks(fontsize = 8)\n",
    "plt.yticks(fontsize = 8)\n",
    "frame_tick()\n",
    "plt.xlabel(r'Velocity ($mm/s$)')\n",
    "plt.ylabel(r'Occurence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "azb4TEFwUGm-",
    "outputId": "abdb452e-92a6-47e7-a959-c83c580d5df2"
   },
   "outputs": [],
   "source": [
    "# Examine features present in the dataset\n",
    "\n",
    "unique, counts = np.unique(csv['Material'], return_counts = True)\n",
    "pprint(set(zip(unique, counts)))\n",
    "print(\"Features: \")\n",
    "for col in csv.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4Hv0fHnUGm-",
    "outputId": "f557ca58-6108-4a6d-df45-45b8255ea97b"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi = 300)\n",
    "materials = csv['Material'].value_counts()\n",
    "dir(materials)\n",
    "materials.keys()\n",
    "#breakpoint()\n",
    "y_pos = np.arange(len(materials.keys()))\n",
    "y_pos_str = np.array([key for key  in materials.keys()], dtype = 'object')\n",
    "print(y_pos)\n",
    "#plt.bar(y_pos, materials)\n",
    "plt.xticks(y_pos, y_pos_str, fontsize = 7)\n",
    "plt.xlim(-0.5, 5.5)\n",
    "plt.bar(y_pos, materials, edgecolor = 'k')\n",
    "\n",
    "plt.ylabel(\"Occurence\")\n",
    "plt.xlabel(\"Material\")\n",
    "frame_tick()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FDHb0AnUGm_",
    "outputId": "b8f2030e-b0f0-4a9d-ebe7-a7f0e4ec08bb"
   },
   "outputs": [],
   "source": [
    "materials = csv['Material'].value_counts()\n",
    "materials.keys()\n",
    "#len(materials.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQ2MJwKkUGm_",
    "outputId": "00f86b42-40ce-427c-db6b-5002a215085c"
   },
   "outputs": [],
   "source": [
    "for i,j in zip(y_pos, materials.keys()):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "srIvPdVpUGnA",
    "outputId": "d801cacc-e5e6-456c-cab8-fd97e5953d61"
   },
   "outputs": [],
   "source": [
    "# Examine data categories\n",
    "\n",
    "print('Process')\n",
    "unique, counts = np.unique(csv['Process'], return_counts = True)\n",
    "pprint(set(zip(unique, counts)))\n",
    "print('Material')\n",
    "\n",
    "unique, counts = np.unique(csv['Material'], return_counts = True)\n",
    "pprint(set(zip(unique, counts)))\n",
    "print('paper ID')\n",
    "\n",
    "unique, counts = np.unique(csv['paper ID'], return_counts = True)\n",
    "pprint(set(zip(unique, counts)))\n",
    "\n",
    "shape = np.array(csv['meltpool shape'], dtype = 'str')\n",
    "\n",
    "unique, counts = np.unique(shape, return_counts = True)\n",
    "pprint(set(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOCfmXkTUGnA",
    "outputId": "facb8f48-eb1c-45b8-b79c-34f1ab3c537b"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi = 300)\n",
    "defects = csv['meltpool shape'].value_counts()\n",
    "dir(materials)\n",
    "materials.keys()\n",
    "defects_pos = np.arange(len(defects.keys()))\n",
    "plt.bar(defects_pos, defects, edgecolor = 'k')\n",
    "plt.xticks(defects_pos, defects.keys(), fontsize=8)\n",
    "plt.ylabel(\"Occurence\")\n",
    "plt.xlabel(\"Melt pool shape\")\n",
    "frame_tick()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkgrsyesUGnA",
    "outputId": "302932cc-3488-43ac-8b94-717de6978298"
   },
   "outputs": [],
   "source": [
    "# Examine distribution of features\n",
    "for col in csv.columns:\n",
    "    values = csv[col]\n",
    "    num_present = len([value for value in values if not pd.isnull(value)])\n",
    "    total = len(values)\n",
    "    parameter = col\n",
    "    print('{:.1f} % samples has '.format(100*num_present/total) + parameter + ' value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-gHiwZ4UGnB",
    "outputId": "921cf4e2-d9c9-4d82-85d4-2e5692419df9"
   },
   "outputs": [],
   "source": [
    "atomic_features = []\n",
    "for col in csv.columns:\n",
    "   # print('%' in col)\n",
    "    if '%' in col:\n",
    "        atomic_features.append(col)\n",
    "atomic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KTitPz6UGnB",
    "outputId": "33661385-ca0d-45b9-db17-f7f045095cd1"
   },
   "outputs": [],
   "source": [
    "materials_ohe = [np.zeros(len(csv)) for key in materials.keys()]\n",
    "len(materials_ohe)\n",
    "materials_ohe = np.array(materials_ohe).T\n",
    "print(len(materials_ohe))\n",
    "material_pos = np.arange(len(materials.keys()))\n",
    "for idx in range(len(csv)):\n",
    "    for j_idx in range(len(material_pos)):\n",
    "        if csv['Material'].iloc[idx] == materials.keys()[j_idx]:\n",
    "            materials_ohe[idx,j_idx] = 1 \n",
    "print(np.argmax(materials_ohe, axis = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ryySGGtrUGnB",
    "outputId": "1d7a661a-da47-44ae-ea75-9cd506305396"
   },
   "outputs": [],
   "source": [
    "csv.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygMOQJJaUGnC"
   },
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tksfvkAHUGnC"
   },
   "source": [
    "## Helper functions for selecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8krHRLkjUGnC"
   },
   "outputs": [],
   "source": [
    "# select subset of data containing material, process, etc\n",
    "# select_subset generalizes this for any feature\n",
    "def select_material(csv, material):\n",
    "    material_csv = csv.loc[csv['Material'] == material]\n",
    "\n",
    "    return material_csv\n",
    "\n",
    "def select_process(csv, process):\n",
    "    process_csv = csv.loc[csv['Process'] == process]\n",
    "    return process_csv\n",
    "\n",
    "def select_subset(csv, feature, value):\n",
    "    select_csv = csv.loc[csv[feature] == value]\n",
    "    return select_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DElaQanhUGnC"
   },
   "outputs": [],
   "source": [
    "def select_parameters(new_csv, parameter_list, label_col):\n",
    "    '''\n",
    "    Select data with valid values for each parameter in parameter_list, and\n",
    "    select the feature in label_col as the prediction feature\n",
    "    \n",
    "    Arguments:\n",
    "    new_csv: data csv to be processed (Pandas DataFrame)\n",
    "    parameter_list: list of strings corresponding to feature names\n",
    "    label_col: string corresponding to feature name\n",
    "    \n",
    "    Returns:\n",
    "    X: n x m numpy array of data features with n samples and m features\n",
    "    y: n x 1 numpy array of data labels\n",
    "    '''\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(new_csv)):\n",
    "        success, features, label = extract_features(new_csv.iloc[i], parameter_list, label_col)\n",
    "        \n",
    "        if success < 0:\n",
    "            continue\n",
    "        else:\n",
    "            data_list.append(features)\n",
    "            label_list.append(label)\n",
    "    X = np.array(np.squeeze(data_list))  \n",
    "    \n",
    "    y = np.array(label_list)\n",
    "    \n",
    "    return(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_csv = select_subset(class_csv, 'Sub-process','SLM')\n",
    "parameter_list = ['Power', 'Velocity', 'layer thickness']\n",
    "label_col = 'meltpool shape'\n",
    "X, y = select_parameters(new_csv, parameter_list, label_col)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AdditiveNet_elementalfeatures_updatedcsv.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
