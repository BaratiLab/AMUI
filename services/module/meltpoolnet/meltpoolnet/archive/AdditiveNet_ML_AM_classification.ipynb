{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vupfd40eUGm0"
   },
   "source": [
    "# Machine Learning for Additive Manufacturing: Melt Pool Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Hnicu28vUGm1"
   },
   "source": [
    "Load in relevant modules\n",
    "\n",
    "\n",
    "python package dependencies: ```mendeleev, matplotlib, pandas, numpy, pylab, pprint, sklearn, scipy, os```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lpjSZzo2UGm3",
    "outputId": "8d6a617a-c45e-4d9d-f29d-3608c0df78ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/cmu/DATA1/francis/Previous Projects/AdditiveNet/CNN_AM_Project/AdditiveNet'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from pprint import pprint\n",
    "from pylab import gca # For adjusting frame width only\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from meltpoolnet.utils.plotting_utils import frame_tick\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mINPDSBmUGm6"
   },
   "source": [
    "# Load in data, perform basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UhE9tnunUGm6",
    "outputId": "017e1ba1-43c0-4d18-feed-6a5251f17094"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory:  /media/cmu/DATA1/francis/Previous Projects/AdditiveNet/CNN_AM_Project/AdditiveNet\n"
     ]
    }
   ],
   "source": [
    "# Load in the csv data, download from Google Sheets and store in directory\n",
    "print(\"Current directory: \", os.getcwd())\n",
    "csv = pd.read_csv('meltpoolgeometry.csv') \n",
    "csv1 = pd.read_csv('meltpoolgeometry.csv')\n",
    "csv2 = pd.read_csv('meltpoolclassification.csv')\n",
    "regressioncsv =  csv1\n",
    "class_csv = csv1.append(csv2)\n",
    "materials = csv['Material'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys Present in CSV:\n",
      "Material\n",
      "Process\n",
      "Sub-process\n",
      "Power\n",
      "Velocity\n",
      "Hatch spacing\n",
      "depth of meltpool\n",
      "width of melt pool\n",
      "length of melt pool\n",
      "d/l\n",
      "d/w\n",
      "l/w\n",
      "E (J/mm)\n",
      "E (J/mm3)\n",
      "layer thickness\n",
      "beam D\n",
      "absorption coefficient\n",
      "absorption coefficient 2\n",
      "density\n",
      "Cp\n",
      "k\n",
      "melting T\n",
      "minimal absorptivity\n",
      "meltpool shape\n",
      "spatter\n",
      "Y (wt%)\n",
      "Zn (wt%)\n",
      "Mg (wt%)\n",
      "Si (wt%)\n",
      "Al (wt%)\n",
      "Sn (wt%)\n",
      "Zr (wt%)\n",
      "W (wt%)\n",
      "Ti (wt%)\n",
      "V (wt%)\n",
      "Co (wt%)\n",
      "Cu (wt%)\n",
      "Ta (wt%)\n",
      "Nb (wt%)\n",
      "Ni  (wt.%)\n",
      "Cr  (wt.%)\n",
      "Fe (wt.%)\n",
      "Mn (wt%)\n",
      "Mo (wt.%)\n",
      "D10\n",
      "D50\n",
      "D90\n",
      "paper ID\n",
      "paper\n",
      "porosity\n",
      "relative density\n",
      "comment\n",
      "Unnamed: 52\n"
     ]
    }
   ],
   "source": [
    "print('Keys Present in CSV:')\n",
    "for key in csv.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMaterial\u001b[0m\n",
      "639 entries present in Material SS316L\n",
      "452 entries present in Material Ti-6Al-4V\n",
      "147 entries present in Material IN718\n",
      "103 entries present in Material SS17-4PH\n",
      "97 entries present in Material IN625\n",
      "50 entries present in Material IN738LC\n",
      "41 entries present in Material Hastelloy X\n",
      "35 entries present in Material Cu10Sn\n",
      "29 entries present in Material AlSi10Mg\n",
      "25 entries present in Material Al-2.5Fe\n",
      "24 entries present in Material Al-C-Co-Fe-Mn-Ni\n",
      "24 entries present in Material Tungsten\n",
      "20 entries present in Material Ti-49Al-2Cr-2Nb\n",
      "19 entries present in Material HCP Cu\n",
      "18 entries present in Material Invar36\n",
      "16 entries present in Material SS304\n",
      "12 entries present in Material WE43\n",
      "12 entries present in Material MS1-\n",
      "9 entries present in Material CMSX-4\n",
      "8 entries present in Material TiC/Inconel 718\n",
      "6 entries present in Material SS304L\n",
      "6 entries present in Material Ti6242\n",
      "5 entries present in Material K403 superalloy\n",
      "4 entries present in Material Ti-45Al\n",
      "3 entries present in Material 4140 steel\n",
      "2 entries present in Material AA7075\n"
     ]
    }
   ],
   "source": [
    "def print_field_composition(csv_input, field):\n",
    "    print(field) \n",
    "    unique, counts = np.unique(csv_input[field], return_counts = True)\n",
    "    indices = np.argsort(counts)[::-1]\n",
    "    unique_sorted = unique[indices]\n",
    "    counts_sorted = counts[indices]\n",
    "    for i in range(len(unique_sorted)):\n",
    "        print(f'{counts_sorted[i]} entries present in {field} {unique_sorted[i]}')\n",
    "print_field_composition(csv, 'Material')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LkgrsyesUGnA",
    "outputId": "302932cc-3488-43ac-8b94-717de6978298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 % samples have Material value\n",
      "100.0 % samples have Process value\n",
      "100.0 % samples have Sub-process value\n",
      "100.0 % samples have Power value\n",
      "100.0 % samples have Velocity value\n",
      "23.7 % samples have Hatch spacing value\n",
      "80.5 % samples have depth of meltpool value\n",
      "63.6 % samples have width of melt pool value\n",
      "17.5 % samples have length of melt pool value\n",
      "64.2 % samples have d/l value\n",
      "49.7 % samples have d/w value\n",
      "35.1 % samples have l/w value\n",
      "94.0 % samples have E (J/mm) value\n",
      "20.4 % samples have E (J/mm3) value\n",
      "79.7 % samples have layer thickness value\n",
      "81.9 % samples have beam D value\n",
      "59.5 % samples have absorption coefficient value\n",
      "63.1 % samples have absorption coefficient 2 value\n",
      "97.3 % samples have density value\n",
      "97.3 % samples have Cp value\n",
      "97.1 % samples have k value\n",
      "100.0 % samples have melting T value\n",
      "72.5 % samples have minimal absorptivity value\n",
      "43.9 % samples have meltpool shape value\n",
      "0.5 % samples have spatter value\n",
      "100.0 % samples have Y (wt%) value\n",
      "100.0 % samples have Zn (wt%) value\n",
      "100.0 % samples have Mg (wt%) value\n",
      "100.0 % samples have Si (wt%) value\n",
      "100.0 % samples have Al (wt%) value\n",
      "100.0 % samples have Sn (wt%) value\n",
      "100.0 % samples have Zr (wt%) value\n",
      "100.0 % samples have W (wt%) value\n",
      "100.0 % samples have Ti (wt%) value\n",
      "100.0 % samples have V (wt%) value\n",
      "100.0 % samples have Co (wt%) value\n",
      "100.0 % samples have Cu (wt%) value\n",
      "100.0 % samples have Ta (wt%) value\n",
      "100.0 % samples have Nb (wt%) value\n",
      "100.0 % samples have Ni  (wt.%) value\n",
      "100.0 % samples have Cr  (wt.%) value\n",
      "100.0 % samples have Fe (wt.%) value\n",
      "100.0 % samples have Mn (wt%) value\n",
      "100.0 % samples have Mo (wt.%) value\n",
      "3.6 % samples have D10 value\n",
      "2.3 % samples have D50 value\n",
      "2.3 % samples have D90 value\n",
      "100.0 % samples have paper ID value\n",
      "43.5 % samples have paper value\n",
      "0.9 % samples have porosity value\n",
      "5.3 % samples have relative density value\n",
      "0.7 % samples have comment value\n",
      "97.3 % samples have Unnamed: 52 value\n"
     ]
    }
   ],
   "source": [
    "# Examine distribution of features\n",
    "for col in csv.columns:\n",
    "    values = csv[col]\n",
    "    num_present = len([value for value in values if not pd.isnull(value)])\n",
    "    total = len(values)\n",
    "    parameter = col\n",
    "    print('{:.1f} % samples have '.format(100*num_present/total) + parameter + ' value')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ygMOQJJaUGnC"
   },
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tksfvkAHUGnC"
   },
   "source": [
    "## Helper functions for selecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8krHRLkjUGnC"
   },
   "outputs": [],
   "source": [
    "from meltpoolnet.ml.classification_ml import classify_learn\n",
    "from meltpoolnet.utils.utils import select_subset, select_material, select_process\n",
    "from meltpoolnet.utils.utils import select_parameters, extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory:  /media/cmu/DATA1/francis/Previous Projects/AdditiveNet/CNN_AM_Project/AdditiveNet\n"
     ]
    }
   ],
   "source": [
    "# Load in the csv data, download from Google Sheets and store in directory\n",
    "print(\"Current directory: \", os.getcwd())\n",
    "csv = pd.read_csv('meltpoolgeometry.csv') \n",
    "csv1 = pd.read_csv('meltpoolgeometry.csv')\n",
    "csv2 = pd.read_csv('meltpoolclassification.csv')\n",
    "regressioncsv =  csv1\n",
    "class_csv = csv1.append(csv2)\n",
    "materials = csv['Material'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine distribution of features\n",
    "for col in csv.columns:\n",
    "    values = csv[col]\n",
    "    num_present = len([value for value in values if not pd.isnull(value)])\n",
    "    total = len(values)\n",
    "    parameter = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example use case\n",
    "new_csv = select_subset(class_csv, 'Sub-process','SLM')\n",
    "parameter_list = ['Power', 'Velocity', 'layer thickness']\n",
    "label_col = 'meltpool shape'\n",
    "X, y = select_parameters(new_csv, parameter_list, label_col)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification task \n",
    "\n",
    "Predicts the melt pool shape based on features of the build process. The potential classes are `spatter`, `balling`, `keyhole`, `desirable`, and `LOF`  describing either the type of defect, or indicating that there is  no defect in the `desirable` case. The following algorithms are used to generate predictions, and their accuracies are compared.\n",
    "\n",
    "\n",
    "- Random Forests 'RF'\n",
    "\n",
    "\n",
    "- Gaussian Process Classification 'GPC'\n",
    "\n",
    "\n",
    "- Support Vector Classification 'SVC'\n",
    "\n",
    "\n",
    "- Logistic Regression 'Logistic Regression'\n",
    "\n",
    "\n",
    "- Gradient Boosted Random Forest 'GB'\n",
    "\n",
    "\n",
    "\n",
    "- Neural Network 'NN'\n",
    "\n",
    "The base ML case considers process and thermodynamic parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Y (wt%)',\n",
       " 'Zn (wt%)',\n",
       " 'Mg (wt%)',\n",
       " 'Si (wt%)',\n",
       " 'Al (wt%)',\n",
       " 'Sn (wt%)',\n",
       " 'Zr (wt%)',\n",
       " 'W (wt%)',\n",
       " 'Ti (wt%)',\n",
       " 'V (wt%)',\n",
       " 'Co (wt%)',\n",
       " 'Cu (wt%)',\n",
       " 'Ta (wt%)',\n",
       " 'Nb (wt%)',\n",
       " 'Ni  (wt.%)',\n",
       " 'Cr  (wt.%)',\n",
       " 'Fe (wt.%)',\n",
       " 'Mn (wt%)',\n",
       " 'Mo (wt.%)']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_features = []\n",
    "for col in csv.columns:\n",
    "   # print('%' in col)\n",
    "    if '%' in col:\n",
    "        atomic_features.append(col)\n",
    "atomic_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration with baseline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 29) (252,)\n",
      "RF Train Accuracy: 1.00000 ± 0.00000, Test Accuracy: 0.85678 ± 0.05490\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Define parameters that models will be trained on and value to be predicted\n",
    "parameter_list = ['Power', 'Velocity', 'density', 'Cp', 'k' , 'beam D', 'melting T', 'layer thickness', 'absorption coefficient', 'absorption coefficient 2']\n",
    "parameter_list.extend(atomic_features)\n",
    "label_col = 'meltpool shape'\n",
    "\n",
    "# Form dataset array from dataframe, given parameter_list, label_col\n",
    "# function select_parameters() does this as well\n",
    "\n",
    "data_list = []\n",
    "label_list = []\n",
    "new_csv = select_subset(class_csv, 'Sub-process', 'SLM')\n",
    "\n",
    "test = 0\n",
    "for i in range(len(new_csv)):\n",
    "    success, features, label = extract_features(new_csv.iloc[i], parameter_list, label_col)\n",
    "    if success < 0:\n",
    "        continue\n",
    "    else:\n",
    "        test += 1\n",
    "        data_list.append(features)\n",
    "        label_list.append(label)\n",
    "\n",
    "        \n",
    "X= np.array(np.squeeze(data_list))\n",
    "labels = np.unique(label_list)\n",
    "\n",
    "# Define labels from csv file\n",
    "label_id = np.arange(len(labels))\n",
    "class_labels = np.zeros(len(label_list))\n",
    "for idx, sample in enumerate(label_list):\n",
    "    for l_id, lbl in enumerate(labels):\n",
    "        if lbl == sample:\n",
    "            class_labels[idx] = l_id\n",
    "y = np.array(class_labels)\n",
    "\n",
    " \n",
    "class_labels = np.array(class_labels,dtype = 'int')\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "fit_models, train_accuracy, train_accuracy_std, test_accuracy, test_accuracy_std = classify_learn(data = X.reshape(-1, len(X[0])), \n",
    "                                                                                                    labels = y, \n",
    "                                                                                                    label_names = labels,\n",
    "                                                                                                    plot = False, \n",
    "                                                                                                    parameters = parameter_list, \n",
    "                                                                                                    parameter_list  = parameter_list,\n",
    "                                                                                                    title = 'L-PBF', \n",
    "                                                                                                    prefix = 'classification', \n",
    "                                                                                                    model_name = 'RF')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration with thermodynamic parameters, composition, and one hot encoded material features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length in PBF data:  2178\n",
      "Used data points:  358\n",
      "358\n",
      "NN Train Accuracy: 0.96996 ± 0.01376, Test Accuracy: 0.81549 ± 0.04534\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Define parameters that models will be trained on and value to be predicted\n",
    "parameter_list = ['Power', 'Velocity', 'density', 'Cp', 'k' , 'beam D', 'melting T', 'layer thickness', 'absorption coefficient']\n",
    "parameter_list.extend(atomic_features)\n",
    "label_col = 'meltpool shape'\n",
    "\n",
    "\n",
    "#Form dataset array from dataframe, given parameter_list, label_col\n",
    "# function select_parameters() does this as well\n",
    "data_list = []\n",
    "label_list = []\n",
    "materials_present = []\n",
    "\n",
    "new_csv = select_process(class_csv, 'PBF')\n",
    "test = 0\n",
    "for i in range(len(new_csv)):\n",
    "    success, features, label = extract_features(new_csv.iloc[i], parameter_list, label_col)\n",
    "    if success < 0:\n",
    "      #  print(\"CONTINUE\")\n",
    "        continue\n",
    "    else:\n",
    "        test += 1\n",
    "        data_list.append(features)\n",
    "        label_list.append(label)\n",
    "        materials_present.append(new_csv['Material'].iloc[i])\n",
    "\n",
    "print('length in PBF data: ', len(new_csv))\n",
    "print('Used data points: ', test)\n",
    "X= np.array(np.squeeze(data_list))\n",
    "labels = np.unique(label_list)\n",
    "\n",
    "# Define labels from csv file\n",
    "label_id = np.arange(len(labels))\n",
    "class_labels = np.zeros(len(label_list))\n",
    "for idx, sample in enumerate(label_list):\n",
    "    for l_id, lbl in enumerate(labels):\n",
    "        if lbl == sample:\n",
    "            class_labels[idx] = l_id\n",
    "y = np.array(class_labels)\n",
    "\n",
    "# Define One Hot Encoding of materials\n",
    "materials_ohe = [np.zeros(len(materials_present)) for key in materials.keys()]\n",
    "\n",
    "materials_ohe = np.array(materials_ohe).T\n",
    "\n",
    "print(len(materials_ohe))\n",
    "material_pos = np.arange(len(materials.keys()))\n",
    "for idx in range(len(materials_present)):\n",
    "    for j_idx in range(len(material_pos)):\n",
    "        if materials_present[idx] == materials.keys()[j_idx]:\n",
    "            materials_ohe[idx,j_idx] = 1 \n",
    "\n",
    " \n",
    "class_labels = np.array(class_labels,dtype = 'int')\n",
    "\n",
    "\n",
    "fit_models_wtohe, \\\n",
    "    train_accuracy_wtohe, \\\n",
    "        train_accuracy_std_wtohe, \\\n",
    "            test_accuracy_wtohe, \\\n",
    "                test_accuracy_std_wtohe = classify_learn(X.reshape(-1, len(X[0])), \n",
    "                                                        y, \n",
    "                                                        labels, \n",
    "                                                        parameters = parameter_list, \n",
    "                                                        parameter_list = parameter_list,\n",
    "                                                        title = 'PBF, PT_wt_OHE', \n",
    "                                                        plot = False, \n",
    "                                                        prefix = 'classification', \n",
    "                                                        model_name = 'NN')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AdditiveNet_elementalfeatures_updatedcsv.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
