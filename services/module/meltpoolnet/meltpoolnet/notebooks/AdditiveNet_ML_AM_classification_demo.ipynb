{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vupfd40eUGm0"
   },
   "source": [
    "# Machine Learning for Additive Manufacturing: Melt Pool Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Hnicu28vUGm1"
   },
   "source": [
    "Load in relevant modules\n",
    "\n",
    "\n",
    "python package dependencies: ```mendeleev, matplotlib, pandas, numpy, pylab, pprint, sklearn, scipy, os```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpjSZzo2UGm3",
    "outputId": "8d6a617a-c45e-4d9d-f29d-3608c0df78ee"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pylab import * # For adjusting frame width only\n",
    "from meltpoolnet.ml.classification_ml import classify_learn\n",
    "from meltpoolnet.utils.utils import select_subset, select_process\n",
    "from meltpoolnet.utils.utils import select_parameters, extract_features\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mINPDSBmUGm6"
   },
   "source": [
    "# Load in data, perform basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhE9tnunUGm6",
    "outputId": "017e1ba1-43c0-4d18-feed-6a5251f17094"
   },
   "outputs": [],
   "source": [
    "# Load in the csv data, download from Google Sheets and store in directory\n",
    "dataset_dir = os.path.join(os.path.abspath(''), '../../', 'datasets')\n",
    "csv = pd.read_csv(os.path.join(dataset_dir, 'meltpoolgeometry.csv')) \n",
    "csv1 = pd.read_csv(os.path.join(dataset_dir, 'meltpoolgeometry.csv'))\n",
    "csv2 = pd.read_csv(os.path.join(dataset_dir, 'meltpoolclassification.csv'))\n",
    "regressioncsv =  csv1\n",
    "class_csv = csv1.append(csv2)\n",
    "materials = csv['Material'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Keys Present in CSV:')\n",
    "for key in csv.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_field_composition(csv_input, field):\n",
    "    print(field) \n",
    "    unique, counts = np.unique(csv_input[field], return_counts = True)\n",
    "    indices = np.argsort(counts)[::-1]\n",
    "    unique_sorted = unique[indices]\n",
    "    counts_sorted = counts[indices]\n",
    "    for i in range(len(unique_sorted)):\n",
    "        print(f'{counts_sorted[i]} entries present in {field} {unique_sorted[i]}')\n",
    "print_field_composition(csv, 'Material')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkgrsyesUGnA",
    "outputId": "302932cc-3488-43ac-8b94-717de6978298"
   },
   "outputs": [],
   "source": [
    "# Examine distribution of features\n",
    "for col in csv.columns:\n",
    "    values = csv[col]\n",
    "    num_present = len([value for value in values if not pd.isnull(value)])\n",
    "    total = len(values)\n",
    "    parameter = col\n",
    "    print('{:.1f} % samples have '.format(100*num_present/total) + parameter + ' value')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ygMOQJJaUGnC"
   },
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tksfvkAHUGnC"
   },
   "source": [
    "## Helper functions for selecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the csv data, download from Google Sheets and store in directory\n",
    "print(\"Current directory: \", os.getcwd())\n",
    "dataset_dir = os.path.join(os.path.abspath(''), '../../', 'datasets')\n",
    "csv = pd.read_csv(os.path.join(dataset_dir, 'meltpoolgeometry.csv')) \n",
    "csv1 = pd.read_csv(os.path.join(dataset_dir, 'meltpoolgeometry.csv'))\n",
    "csv2 = pd.read_csv(os.path.join(dataset_dir, 'meltpoolclassification.csv'))\n",
    "regressioncsv =  csv1\n",
    "class_csv = csv1.append(csv2)\n",
    "materials = csv['Material'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine distribution of features\n",
    "for col in csv.columns:\n",
    "    values = csv[col]\n",
    "    num_present = len([value for value in values if not pd.isnull(value)])\n",
    "    total = len(values)\n",
    "    parameter = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example use case\n",
    "new_csv = select_subset(class_csv, 'Sub-process','SLM')\n",
    "parameter_list = ['Power', 'Velocity', 'layer thickness']\n",
    "label_col = 'meltpool shape'\n",
    "X, y = select_parameters(new_csv, parameter_list, label_col)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification task \n",
    "\n",
    "Predicts the melt pool shape based on features of the build process. The potential classes are `spatter`, `balling`, `keyhole`, `desirable`, and `LOF`  describing either the type of defect, or indicating that there is  no defect in the `desirable` case. The following algorithms are used to generate predictions, and their accuracies are compared.\n",
    "\n",
    "\n",
    "- Random Forests 'RF'\n",
    "\n",
    "\n",
    "- Gaussian Process Classification 'GPC'\n",
    "\n",
    "\n",
    "- Support Vector Classification 'SVC'\n",
    "\n",
    "\n",
    "- Logistic Regression 'Logistic Regression'\n",
    "\n",
    "\n",
    "- Gradient Boosted Random Forest 'GB'\n",
    "\n",
    "\n",
    "\n",
    "- Neural Network 'NN'\n",
    "\n",
    "The base ML case considers process and thermodynamic parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_features = []\n",
    "for col in csv.columns:\n",
    "   # print('%' in col)\n",
    "    if '%' in col:\n",
    "        atomic_features.append(col)\n",
    "atomic_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration with baseline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Define parameters that models will be trained on and value to be predicted\n",
    "parameter_list = ['Power', 'Velocity', 'density', 'Cp', 'k' , 'beam D', 'melting T', 'layer thickness', 'absorption coefficient', 'absorption coefficient 2']\n",
    "parameter_list.extend(atomic_features)\n",
    "label_col = 'meltpool shape'\n",
    "\n",
    "# Form dataset array from dataframe, given parameter_list, label_col\n",
    "# function select_parameters() does this as well\n",
    "\n",
    "data_list = []\n",
    "label_list = []\n",
    "new_csv = select_subset(class_csv, 'Sub-process', 'SLM')\n",
    "\n",
    "test = 0\n",
    "for i in range(len(new_csv)):\n",
    "    success, features, label = extract_features(new_csv.iloc[i], parameter_list, label_col)\n",
    "    if success < 0:\n",
    "        continue\n",
    "    else:\n",
    "        test += 1\n",
    "        data_list.append(features)\n",
    "        label_list.append(label)\n",
    "\n",
    "        \n",
    "X= np.array(np.squeeze(data_list))\n",
    "labels = np.unique(label_list)\n",
    "\n",
    "# Define labels from csv file\n",
    "label_id = np.arange(len(labels))\n",
    "class_labels = np.zeros(len(label_list))\n",
    "for idx, sample in enumerate(label_list):\n",
    "    for l_id, lbl in enumerate(labels):\n",
    "        if lbl == sample:\n",
    "            class_labels[idx] = l_id\n",
    "y = np.array(class_labels)\n",
    "\n",
    " \n",
    "class_labels = np.array(class_labels,dtype = 'int')\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "fit_models, train_accuracy, train_accuracy_std, test_accuracy, test_accuracy_std = classify_learn(data = X.reshape(-1, len(X[0])), \n",
    "                                                                                                    labels = y, \n",
    "                                                                                                    label_names = labels,\n",
    "                                                                                                    plot = False, \n",
    "                                                                                                    parameters = parameter_list, \n",
    "                                                                                                    parameter_list  = parameter_list,\n",
    "                                                                                                    title = 'L-PBF', \n",
    "                                                                                                    prefix = 'classification', \n",
    "                                                                                                    model_name = 'RF')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration with thermodynamic parameters, composition, and one hot encoded material features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Define parameters that models will be trained on and value to be predicted\n",
    "parameter_list = ['Power', 'Velocity', 'density', 'Cp', 'k' , 'beam D', 'melting T', 'layer thickness', 'absorption coefficient']\n",
    "parameter_list.extend(atomic_features)\n",
    "label_col = 'meltpool shape'\n",
    "\n",
    "\n",
    "#Form dataset array from dataframe, given parameter_list, label_col\n",
    "# function select_parameters() does this as well\n",
    "data_list = []\n",
    "label_list = []\n",
    "materials_present = []\n",
    "\n",
    "new_csv = select_process(class_csv, 'PBF')\n",
    "test = 0\n",
    "for i in range(len(new_csv)):\n",
    "    success, features, label = extract_features(new_csv.iloc[i], parameter_list, label_col)\n",
    "    if success < 0:\n",
    "      #  print(\"CONTINUE\")\n",
    "        continue\n",
    "    else:\n",
    "        test += 1\n",
    "        data_list.append(features)\n",
    "        label_list.append(label)\n",
    "        materials_present.append(new_csv['Material'].iloc[i])\n",
    "\n",
    "print('length in PBF data: ', len(new_csv))\n",
    "print('Used data points: ', test)\n",
    "X= np.array(np.squeeze(data_list))\n",
    "labels = np.unique(label_list)\n",
    "\n",
    "# Define labels from csv file\n",
    "label_id = np.arange(len(labels))\n",
    "class_labels = np.zeros(len(label_list))\n",
    "for idx, sample in enumerate(label_list):\n",
    "    for l_id, lbl in enumerate(labels):\n",
    "        if lbl == sample:\n",
    "            class_labels[idx] = l_id\n",
    "y = np.array(class_labels)\n",
    "\n",
    "# Define One Hot Encoding of materials\n",
    "materials_ohe = [np.zeros(len(materials_present)) for key in materials.keys()]\n",
    "\n",
    "materials_ohe = np.array(materials_ohe).T\n",
    "\n",
    "print(len(materials_ohe))\n",
    "material_pos = np.arange(len(materials.keys()))\n",
    "for idx in range(len(materials_present)):\n",
    "    for j_idx in range(len(material_pos)):\n",
    "        if materials_present[idx] == materials.keys()[j_idx]:\n",
    "            materials_ohe[idx,j_idx] = 1 \n",
    "\n",
    " \n",
    "class_labels = np.array(class_labels,dtype = 'int')\n",
    "\n",
    "\n",
    "fit_models_wtohe, \\\n",
    "    train_accuracy_wtohe, \\\n",
    "        train_accuracy_std_wtohe, \\\n",
    "            test_accuracy_wtohe, \\\n",
    "                test_accuracy_std_wtohe = classify_learn(X.reshape(-1, len(X[0])), \n",
    "                                                        y, \n",
    "                                                        labels, \n",
    "                                                        parameters = parameter_list, \n",
    "                                                        parameter_list = parameter_list,\n",
    "                                                        title = 'PBF, PT_wt_OHE', \n",
    "                                                        plot = False, \n",
    "                                                        prefix = 'classification', \n",
    "                                                        model_name = 'NN')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AdditiveNet_elementalfeatures_updatedcsv.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
